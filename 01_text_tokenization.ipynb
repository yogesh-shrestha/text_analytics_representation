{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfd87fb",
   "metadata": {},
   "source": [
    "## Text Tokenization\n",
    "<i>Tokens</i> are independent and minimal textual components that have some difinite syntax and semantics. A paragraph of text or a text document has several components including\n",
    "sentences that can be further broken down into clauses, phrases, and words. The most\n",
    "popular tokenization techniques include sentence and word tokenization, which are\n",
    "used to break down a text corpus into sentences, and each sentence into words. Thus,\n",
    "tokenization can be defined as the process of breaking down or splitting textual data into\n",
    "smaller meaningful components called tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53028d56",
   "metadata": {},
   "source": [
    "### Sentence Tokenization\n",
    "<i>Sentence tokenization</i> is the process of splitting a text corpus into sentences that act as\n",
    "the first level of tokens which the corpus is comprised of. This is also known as <i>sentence\n",
    "segmentation</i> , because we try to segment the text into meaningful sentences.\n",
    "\n",
    "There are various ways of performing sentence tokenization. Basic techniques include looking for specific delimiters between sentences, such as a period (.) or a newline character (\\n), and sometimes even a semi-colon (;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67565525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will discuss briefly about the basic syntax, structure and design philosophies.\n",
      "There is a defined hierarchical syntax for Python code which you should remember when writing code!\n",
      "Python is a really powerful programming language!\n"
     ]
    }
   ],
   "source": [
    "# Tokenization with NLTK\n",
    "\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "sample_text = \"\"\"We will discuss briefly about the basic syntax, structure and \\\n",
    "design philosophies. There is a defined hierarchical syntax for Python code \\\n",
    "which you should remember when writing code! Python is a really powerful \\\n",
    "programming language!\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(text=sample_text)\n",
    "for sent in sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a7343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit der Aktion will Trump nach eigenen Worten seinen loyalsten Fans eine weitere Chance bieten, ihre volle Unterstützung seiner “Save America”-Bewegung zum Ausdruck zu bringen.\n",
      "Wozu genau die Mitgliedschaftskarten ihre jeweiligen Inhaber berechtigen, konnte sein Team bislang nicht erklären.\n",
      "Bereits in der Vorwoche verkaufte der ehemalige Präsident auf seiner Webseite signierte Fotos von sich selbst für 45 Dollar.\n",
      "Seine Anhänger zahlen den Preis gern und hoffen inständig auf seine Wiederkandidatur 2024.\n"
     ]
    }
   ],
   "source": [
    "german_text = \"\"\"Mit der Aktion will Trump nach eigenen Worten seinen loyalsten Fans eine \\\n",
    "weitere Chance bieten, ihre volle Unterstützung seiner “Save America”-Bewegung zum Ausdruck \\\n",
    "zu bringen. Wozu genau die Mitgliedschaftskarten ihre jeweiligen Inhaber berechtigen, konnte \\\n",
    "sein Team bislang nicht erklären. Bereits in der Vorwoche verkaufte der ehemalige Präsident auf \\\n",
    "seiner Webseite signierte Fotos von sich selbst für 45 Dollar. Seine Anhänger zahlen den Preis \\\n",
    "gern und hoffen inständig auf seine Wiederkandidatur 2024.\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(text=german_text,language='german')\n",
    "for sent in sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5a05aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit der Aktion will Trump nach eigenen Worten seinen loyalsten Fans eine weitere Chance bieten, ihre volle Unterstützung seiner “Save America”-Bewegung zum Ausdruck zu bringen.\n",
      "Wozu genau die Mitgliedschaftskarten ihre jeweiligen Inhaber berechtigen, konnte sein Team bislang nicht erklären.\n",
      "Bereits in der Vorwoche verkaufte der ehemalige Präsident auf seiner Webseite signierte Fotos von sich selbst für 45 Dollar.\n",
      "Seine Anhänger zahlen den Preis gern und hoffen inständig auf seine Wiederkandidatur 2024.\n"
     ]
    }
   ],
   "source": [
    " ## Regex tokenizer\n",
    "    \n",
    "SENTENCE_TOKENS_PATTERN = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = nltk.tokenize.RegexpTokenizer(\n",
    "            pattern=SENTENCE_TOKENS_PATTERN,\n",
    "            gaps=True)\n",
    "sample_sentences = regex_st.tokenize(german_text)\n",
    "for sent in  sample_sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "182d0acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mit der Aktion will Trump nach eigenen Worten seinen loyalsten Fans eine weitere Chance bieten, ihre volle Unterstützung seiner “Save America”-Bewegung zum Ausdruck zu bringen.\n",
      "Wozu genau die Mitgliedschaftskarten ihre jeweiligen Inhaber berechtigen, konnte sein Team bislang nicht erklären.\n",
      "Bereits in der Vorwoche verkaufte der ehemalige Präsident auf seiner Webseite signierte Fotos von sich selbst für 45 Dollar.\n",
      "Seine Anhänger zahlen den Preis gern und hoffen inständig auf seine Wiederkandidatur 2024.\n"
     ]
    }
   ],
   "source": [
    "# Using spaCy Framework\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "sample_text = \"\"\"We will discuss briefly about the basic syntax, structure and \\\n",
    "design philosophies. There is a defined hierarchical syntax for Python code \\\n",
    "which you should remember when writing code! Python is a really powerful \\\n",
    "programming language!\"\"\"\n",
    "\n",
    "text_spacy = nlp(sample_text)\n",
    "\n",
    "sentences = list(text_spacy.sents)\n",
    "for sent in  sample_sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72ede1",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b0c0e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hours', 'later', ',', 'rumors', 'began', 'to', 'spread', 'in', 'the', 'close-knit', 'community', 'that', 'something', 'had', 'happened', 'to', 'her', 'son', 'in', 'the', 'nearby', 'river', '.', 'Kapessa', '’', 's', 'older', 'sister', 'heard', 'from', 'friends', 'that', 'Kapessa', ',', 'who', 'could', 'not', 'swim', ',', 'may', 'have', 'jumped', 'into', 'the', 'water', ';', 'others', 'alleged', 'that', 'he', 'had', 'been', 'pushed', '.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK word tokenizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "sample_text = \"\"\"Hours later, rumors began to spread in the close-knit community that something \\\n",
    "had happened to her son in the nearby river. Kapessa’s older sister heard from friends that \\\n",
    "Kapessa, who could not swim, may have jumped into the water; others alleged that he had been \\\n",
    "pushed.\"\"\"\n",
    "words = word_tokenize(sample_text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2b03157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hours', 'later', ',', 'rumors', 'began', 'to', 'spread', 'in', 'the', 'close-knit', 'community', 'that', 'something', 'had', 'happened', 'to', 'her', 'son', 'in', 'the', 'nearby', 'river.', 'Kapessa’s', 'older', 'sister', 'heard', 'from', 'friends', 'that', 'Kapessa', ',', 'who', 'could', 'not', 'swim', ',', 'may', 'have', 'jumped', 'into', 'the', 'water', ';', 'others', 'alleged', 'that', 'he', 'had', 'been', 'pushed', '.']\n"
     ]
    }
   ],
   "source": [
    "# Treebank word Tokenizer\n",
    "\n",
    "sample_text = \"\"\"Hours later, rumors began to spread in the close-knit community that something \\\n",
    "had happened to her son in the nearby river. Kapessa’s older sister heard from friends that \\\n",
    "Kapessa, who could not swim, may have jumped into the water; others alleged that he had been \\\n",
    "pushed.\"\"\"\n",
    "\n",
    "tokenizer = nltk.TreebankWordTokenizer()\n",
    "words = tokenizer.tokenize(sample_text)\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5dff956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hours', 'later', 'rumors', 'began', 'to', 'spread', 'in', 'the', 'close', 'knit', 'community', 'that', 'something', 'had', 'happened', 'to', 'her', 'son', 'in', 'the', 'nearby', 'river', 'Kapessa', 's', 'older', 'sister', 'heard', 'from', 'friends', 'that', 'Kapessa', 'who', 'could', 'not', 'swim', 'may', 'have', 'jumped', 'into', 'the', 'water', 'others', 'alleged', 'that', 'he', 'had', 'been', 'pushed']\n",
      "['Hours', 'later,', 'rumors', 'began', 'to', 'spread', 'in', 'the', 'close-knit', 'community', 'that', 'something', 'had', 'happened', 'to', 'her', 'son', 'in', 'the', 'nearby', 'river.', 'Kapessa’s', 'older', 'sister', 'heard', 'from', 'friends', 'that', 'Kapessa,', 'who', 'could', 'not', 'swim,', 'may', 'have', 'jumped', 'into', 'the', 'water;', 'others', 'alleged', 'that', 'he', 'had', 'been', 'pushed.']\n"
     ]
    }
   ],
   "source": [
    "# Regexp Word Tokenizer\n",
    "sample_text = \"\"\"Hours later, rumors began to spread in the close-knit community that something \\\n",
    "had happened to her son in the nearby river. Kapessa’s older sister heard from friends that \\\n",
    "Kapessa, who could not swim, may have jumped into the water; others alleged that he had been \\\n",
    "pushed.\"\"\"\n",
    "\n",
    "TOKEN_PATTERN = r'\\w+'        \n",
    "regex_wt = nltk.RegexpTokenizer(pattern=TOKEN_PATTERN,\n",
    "                                gaps=False)\n",
    "words = regex_wt.tokenize(sample_text)\n",
    "print(words)\n",
    "\n",
    "\n",
    "GAP_PATTERN = r'\\s+'        \n",
    "regex_wt = nltk.RegexpTokenizer(pattern=GAP_PATTERN,\n",
    "                                gaps=True)\n",
    "words = regex_wt.tokenize(sample_text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1122eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hours, later, ,, rumors, began, to, spread, in, the, close, -, knit, community, that, something, had, happened, to, her, son, in, the, nearby, river, ., Kapessa, ’s, older, sister, heard, from, friends, that, Kapessa, ,, who, could, not, swim, ,, may, have, jumped, into, the, water, ;, others, alleged, that, he, had, been, pushed, .]\n"
     ]
    }
   ],
   "source": [
    "# Spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "sample_text = \"\"\"Hours later, rumors began to spread in the close-knit community that something \\\n",
    "had happened to her son in the nearby river. Kapessa’s older sister heard from friends that \\\n",
    "Kapessa, who could not swim, may have jumped into the water; others alleged that he had been \\\n",
    "pushed.\"\"\"\n",
    "\n",
    "doc = nlp(sample_text)\n",
    "tokens = [token for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3910e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
