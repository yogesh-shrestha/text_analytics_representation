{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0d6904",
   "metadata": {},
   "source": [
    "### Shallow Parsing or Chunking\n",
    "<i>Shallow parsing</i>, also known as <i>light parsing</i> or <i>chunking</i>, is a technique of analyzing the structure of a sentence to break it down into its smallest constituents, which are tokens like words, and group them together into higher-level phrases. In shallow parsing, there\n",
    "is more focus on identifying these phrases or chunks rather than diving into further details of the internal syntax and relations inside each chunk.\n",
    "\n",
    "Based on the hierarchy we depicted earlier, groups of words make up phrases. There are five major categories of phrases:\n",
    "- Noun phrase (NP)\n",
    "- Verb phrase (VP)\n",
    "- Adjective phrase (ADJP)\n",
    "- Adverb phrase (ADVP)\n",
    "- Prepositional phrase (PP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e13b2e",
   "metadata": {},
   "source": [
    "#### Building Shalow Parsers\n",
    "We use several techniques like regular expressions and tagging based learners to build\n",
    "our own shallow parsers. The treebank corpus is available in NLTK with chunk annotations. We load it and then prepare our training and testing datasets.\n",
    "\n",
    "Using the process of <i>chunking</i>, we can use and specify specific patterns to identify what we would want to chunk or segment in a sentence, such as phrases based on specific metadata. <i>Chinking</i> is the reverse of chunking, where we specify which specific tokens we do not want to be a part of any chunk and then form the necessary chunks excluding these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42f2ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Upjohn/NNP)\n",
      "  ,/,\n",
      "  (NP a/DT rumored/VBN target/NN)\n",
      "  within/IN\n",
      "  (NP the/DT drug/NN industry/NN)\n",
      "  ,/,\n",
      "  advanced/VBD\n",
      "  (NP 7\\/8/CD)\n",
      "  to/TO\n",
      "  (NP 38/CD 7\\/8/CD)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank_chunk\n",
    "data = treebank_chunk.chunked_sents()\n",
    "\n",
    "train_data = data[:3500]\n",
    "test_data = data[3500:]\n",
    "print(test_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98505b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT brown/JJ fox/NN)\n",
      "  is/VBZ\n",
      "  quick/JJ\n",
      "  and/CC\n",
      "  he/PRP\n",
      "  is/VBZ\n",
      "  jumping/VBG\n",
      "  over/IN\n",
      "  (NP the/DT lazy/JJ dog/NN))\n",
      "                                                    S                                                \n",
      "   _________________________________________________|_____________________________________            \n",
      "  |       |       |      |      |         |         |              NP                     NP         \n",
      "  |       |       |      |      |         |         |       _______|_______        _______|______     \n",
      "is/VBZ quick/JJ and/CC he/PRP is/VBZ jumping/VBG over/IN The/DT brown/JJ fox/NN the/DT lazy/JJ dog/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.chunk import RegexpParser\n",
    "\n",
    "sample_sentence = 'The brown fox is quick and he is jumping over the lazy dog'\n",
    "\n",
    "tagged_simple_sent = nltk.pos_tag(nltk.word_tokenize(sample_sentence))\n",
    "\n",
    "# Chunking\n",
    "chunk_grammar = \"\"\"\n",
    "                NP: {<DT>?<JJ>*<NN.*>}\n",
    "                \"\"\"\n",
    "rc = RegexpParser(chunk_grammar)\n",
    "c = rc.parse(tagged_simple_sent)\n",
    "print(c)\n",
    "c.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7130d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT)\n",
      "  brown/JJ\n",
      "  (NP fox/NN)\n",
      "  is/VBZ\n",
      "  quick/JJ\n",
      "  (NP and/CC he/PRP)\n",
      "  is/VBZ\n",
      "  (NP jumping/VBG)\n",
      "  over/IN\n",
      "  (NP the/DT)\n",
      "  lazy/JJ\n",
      "  (NP dog/NN))\n",
      "                                                  S                                                      \n",
      "    ______________________________________________|__________________________________________________     \n",
      "   |       |       |       |       |       |      NP     NP           NP             NP       NP     NP  \n",
      "   |       |       |       |       |       |      |      |       _____|____          |        |      |    \n",
      "brown/JJ is/VBZ quick/JJ is/VBZ over/IN lazy/JJ The/DT fox/NN and/CC     he/PRP jumping/VBG the/DT dog/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chinking based on explicit chink patterns\n",
    "chink_grammar = \"\"\"\n",
    "NP:\n",
    "    {<.*>+}             # Chunk everything as NP\n",
    "    }<VBZ|VBD|JJ|IN>+{  # Chink sequences of VBD\\VBZ\\JJ\\IN\n",
    "\"\"\"\n",
    "\n",
    "chink_grammar = \"\"\"\n",
    "NP:\n",
    "    {<.*>+}             # Chunk everything as NP\n",
    "    }<VBZ|VBD|JJ|IN>+{  # Chink sequences of VBD\\VBZ\\JJ\\IN\n",
    "\"\"\"\n",
    "rc = RegexpParser(chink_grammar)\n",
    "c = rc.parse(tagged_simple_sent)\n",
    "print(c)\n",
    "c.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e012dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT brown/JJ fox/NN)\n",
      "  (VP is/VBZ)\n",
      "  (ADJP quick/JJ)\n",
      "  and/CC\n",
      "  he/PRP\n",
      "  (VP is/VBZ jumping/VBG)\n",
      "  (PP over/IN)\n",
      "  (NP the/DT lazy/JJ dog/NN))\n",
      "                                               S                                                         \n",
      "   ____________________________________________|______________________________________________            \n",
      "  |      |              NP             VP     ADJP           VP                PP             NP         \n",
      "  |      |       _______|_______       |       |        _____|_______          |       _______|______     \n",
      "and/CC he/PRP The/DT brown/JJ fox/NN is/VBZ quick/JJ is/VBZ     jumping/VBG over/IN the/DT lazy/JJ dog/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a more generic shallow parser\n",
    "grammar = \"\"\"\n",
    "NP: {<DT>?<JJ>?<NN.*>}  \n",
    "ADJP: {<JJ>}\n",
    "ADVP: {<RB.*>}\n",
    "PP: {<IN>}      \n",
    "VP: {<MD>?<VB.*>+}\n",
    "\"\"\"\n",
    "rc = RegexpParser(grammar)\n",
    "c = rc.parse(tagged_simple_sent)\n",
    "print(c)\n",
    "c.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917feaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  46.1%%\n",
      "    Precision:     19.9%%\n",
      "    Recall:        43.3%%\n",
      "    F-Measure:     27.3%%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the parser\n",
    "print(rc.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169b718",
   "metadata": {},
   "source": [
    "We leverage two chunking utility functions—`tree2conlltags` to get triples of word, tag, and chunk tags for each token and `conlltags2tree` to generate a parse tree from these token triples. The chunk tags use a popular format, known as the IOB format. In this format, you will notice some new notations with I, O, and B prefixes, which is the popular IOB notation used in chunking. It depicts Inside, Outside, and Beginning. The B- prefix before a tag indicates it is the beginning of a chunk; the I- prefix indicates that it is inside a chunk. The O tag indicates that the token does not belong to any chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d82bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP A/DT Lorillard/NNP spokewoman/NN)\n",
      "  said/VBD\n",
      "  ,/,\n",
      "  ``/``\n",
      "  (NP This/DT)\n",
      "  is/VBZ\n",
      "  (NP an/DT old/JJ story/NN)\n",
      "  ./.)\n",
      "-------------------\n",
      "[('A', 'DT', 'B-NP'), ('Lorillard', 'NNP', 'I-NP'), ('spokewoman', 'NN', 'I-NP'), ('said', 'VBD', 'O'), (',', ',', 'O'), ('``', '``', 'O'), ('This', 'DT', 'B-NP'), ('is', 'VBZ', 'O'), ('an', 'DT', 'B-NP'), ('old', 'JJ', 'I-NP'), ('story', 'NN', 'I-NP'), ('.', '.', 'O')]\n",
      "-------------------\n",
      "(S\n",
      "  (NP A/DT Lorillard/NNP spokewoman/NN)\n",
      "  said/VBD\n",
      "  ,/,\n",
      "  ``/``\n",
      "  (NP This/DT)\n",
      "  is/VBZ\n",
      "  (NP an/DT old/JJ story/NN)\n",
      "  ./.)\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk.util import tree2conlltags, conlltags2tree\n",
    "\n",
    "# look at a sample training tagged sentence\n",
    "train_sent = train_data[7]\n",
    "print(train_sent)\n",
    "print('-------------------')\n",
    "# get the (word, POS tag, Chunk tag) triples for each token\n",
    "wtc = tree2conlltags(train_sent)\n",
    "print(wtc)\n",
    "print('-------------------')\n",
    "# get shallow parsed tree back from the WTC triples\n",
    "tree = conlltags2tree(wtc)\n",
    "print(tree)\n",
    "print('-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ac350",
   "metadata": {},
   "source": [
    "Now that we know how these functions work, we define a function called `conll_tag_chunks()` to extract POS and Chunk tags from sentences with chunked annotations and reuse our `combined_taggers()` function from POS tagging to train multiple taggers with backoff taggers, as depicted in the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bde8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conll_tag_chunks(chunk_sents):\n",
    "    tagged_sents = [tree2conlltags(tree) for tree in chunk_sents]\n",
    "    return [[(t, c) for (w, t, c) in sent] for sent in tagged_sents]\n",
    "\n",
    "def combined_tagger(train_data, taggers, backoff=None):\n",
    "    for tagger in taggers:\n",
    "        backoff = tagger(train_data, backoff=backoff)\n",
    "    return backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f9a55",
   "metadata": {},
   "source": [
    "We now define a `NGramTagChunker` class, which will take in tagged sentences\n",
    "as training input, get their WTC triples (word, POS tag, chunk tag), and train a\n",
    "`BigramTagger` with a `UnigramTagger` as the backoff tagger. We also define a `parse()`\n",
    "function to perform shallow parsing on new sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8923b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger, BigramTagger\n",
    "from nltk.chunk import ChunkParserI\n",
    "\n",
    "class NGramTagChunker(ChunkParserI):\n",
    "    def __init__(self, train_sentences, tagger_classes=[UnigramTagger, BigramTagger]):\n",
    "        train_sent_tags = conll_tag_chunks(train_sentences)\n",
    "        self.chunk_tagger = combined_tagger(train_sent_tags, tagger_classes)\n",
    "        \n",
    "    def parse(self, tagged_sentence):\n",
    "        if not tagged_sentence:\n",
    "            return None\n",
    "        pos_tags = [tag for word, tag in tagged_sentence]\n",
    "        chunk_pos_tags = self.chunk_tagger.tag(pos_tags)\n",
    "        chunk_tags = [chunk_tag for (pos_tag, chunk_tag) in chunk_pos_tags]\n",
    "        wpc_tags = [(word, pos_tag, chunk_tag) \n",
    "                    for ((word, pos_tag), chunk_tag) \n",
    "                    in zip(tagged_sentence, chunk_tags)]\n",
    "        return conlltags2tree(wpc_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82d9446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  97.2%%\n",
      "    Precision:     91.4%%\n",
      "    Recall:        94.3%%\n",
      "    F-Measure:     92.8%%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train the shallow parser\n",
    "ntc = NGramTagChunker(train_data)\n",
    "\n",
    "# test parser performance on test data\n",
    "print(ntc.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8191fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP He/PRP)\n",
      "  (VP reckons/VBZ)\n",
      "  (NP the/DT current/JJ account/NN deficit/NN)\n",
      "  (VP will/MD narrow/VB)\n",
      "  (PP to/TO)\n",
      "  (NP only/RB #/# 1.8/CD billion/CD)\n",
      "  (PP in/IN)\n",
      "  (NP September/NNP)\n",
      "  ./.)\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  89.1%%\n",
      "    Precision:     80.3%%\n",
      "    Recall:        86.1%%\n",
      "    F-Measure:     83.1%%\n"
     ]
    }
   ],
   "source": [
    "# Let’s now train and evaluate our parser on the conll2000 corpus\n",
    "\n",
    "from nltk.corpus import conll2000\n",
    "wsj_data = conll2000.chunked_sents()\n",
    "train_wsj_data = wsj_data[:10000]\n",
    "test_wsj_data = wsj_data[10000:]\n",
    "\n",
    "print(train_wsj_data[10])\n",
    "\n",
    "# train the shallow parser\n",
    "tc = NGramTagChunker(train_wsj_data)\n",
    "# test performance on the test data\n",
    "print(tc.evaluate(test_wsj_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71b46c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT brown/JJ fox/NN)\n",
      "  is/VBZ\n",
      "  (NP quick/JJ)\n",
      "  and/CC\n",
      "  (NP he/PRP)\n",
      "  is/VBZ\n",
      "  jumping/VBG\n",
      "  over/IN\n",
      "  (NP the/DT lazy/JJ dog/NN))\n"
     ]
    }
   ],
   "source": [
    "# parse our sample sentence\n",
    "\n",
    "import spacy\n",
    "\n",
    "sample_sentence = 'The brown fox is quick and he is jumping over the lazy dog'\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp(sample_sentence)\n",
    "\n",
    "tagged_sentence = [(word.text, word.tag_) for word in doc]\n",
    "tree = ntc.parse(tagged_sentence)\n",
    "print(tree)\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7242e2f7",
   "metadata": {},
   "source": [
    "### Dependency Parsing\n",
    "In dependency-based parsing, we try to use dependency-based grammars to analyze and infer both structure and semantic dependencies and relationships between tokens in a sentence. Dependency grammars help us annotate sentences with dependency tags, which are one-to-one mappings between tokens signifying dependencies between them.\n",
    "\n",
    "The basic principle behind a dependency grammar is that in any sentence in the language, all words except one have some relationship or dependency on other words in the sentence. The word that has no dependency is called the root of the sentence. The verb is taken as the root of the sentence in most cases. All the other words are directly or indirectly linked to the root verb using links , which are the dependencies.\n",
    "\n",
    "https://universaldependencies.org/en/dep/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f7a5fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  <----  det  <----  fox\n",
      "brown  <----  amod  <----  fox\n",
      "fox  <----  nsubj  <----  is\n",
      "is  <----  ROOT  <----  is\n",
      "quick  <----  acomp  <----  is\n",
      "and  <----  cc  <----  is\n",
      "he  <----  nsubj  <----  jumping\n",
      "is  <----  aux  <----  jumping\n",
      "jumping  <----  conj  <----  is\n",
      "over  <----  prep  <----  jumping\n",
      "the  <----  det  <----  dog\n",
      "lazy  <----  amod  <----  dog\n",
      "dog  <----  pobj  <----  over\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"77feff819c31411ea2d9df8d10abb74f-0\" class=\"displacy\" width=\"1480\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">he</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">jumping</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L64,214.0 76,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L174,214.0 186,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-2\" stroke-width=\"2px\" d=\"M290,222.0 C290,167.0 365.0,167.0 365.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,224.0 L284,214.0 296,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-3\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M475.0,224.0 L481.0,214.0 469.0,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-4\" stroke-width=\"2px\" d=\"M400,222.0 C400,112.0 590.0,112.0 590.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M590.0,224.0 L596.0,214.0 584.0,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,112.0 920.0,112.0 920.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L724,214.0 736,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-6\" stroke-width=\"2px\" d=\"M840,222.0 C840,167.0 915.0,167.0 915.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,224.0 L834,214.0 846,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-7\" stroke-width=\"2px\" d=\"M400,222.0 C400,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L936.0,214.0 924.0,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-8\" stroke-width=\"2px\" d=\"M950,222.0 C950,167.0 1025.0,167.0 1025.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1025.0,224.0 L1031.0,214.0 1019.0,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,112.0 1360.0,112.0 1360.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1164,214.0 1176,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-10\" stroke-width=\"2px\" d=\"M1280,222.0 C1280,167.0 1355.0,167.0 1355.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1280,224.0 L1274,214.0 1286,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77feff819c31411ea2d9df8d10abb74f-0-11\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,57.0 1365.0,57.0 1365.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77feff819c31411ea2d9df8d10abb74f-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1365.0,224.0 L1371.0,214.0 1359.0,214.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(\"The brown fox is quick and he is jumping over the lazy dog\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, ' <---- ', token.dep_, ' <---- ', token.head.text)\n",
    "    \n",
    "spacy.displacy.render(doc, style='dep',\n",
    "                     jupyter=True,\n",
    "                    options={'distance': 110,\n",
    "                        'arrow_stroke': 2,\n",
    "                        'arrow_width': 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d3592",
   "metadata": {},
   "source": [
    "### Constituent Parsing\n",
    "Constituent based grammars are used to analyze and determine the constituents that\n",
    "a sentence is composed of. Besides determining the constituents, another important\n",
    "objective is to determine the internal structure of these constituents and how they link\n",
    "to each other. In general, constituency based grammar helps specify how we can break a sentence\n",
    "into various constituents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "531ee423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-0557e10e9d7b>:5: DeprecationWarning: The StanfordParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.\n",
      "  scp = StanfordParser(path_to_jar='C:/Users/shres/PythonDoc/text_analytics/stanford_parser/stanford-parser-full-2015-04-20/stanford-parser.jar',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (NP\n",
      "    (S\n",
      "      (S\n",
      "        (NP (DT The) (JJ brown) (NN fox))\n",
      "        (VP (VBZ is) (ADJP (JJ quick))))\n",
      "      (CC and)\n",
      "      (S\n",
      "        (NP (PRP he))\n",
      "        (VP\n",
      "          (VBZ is)\n",
      "          (VP\n",
      "            (VBG jumping)\n",
      "            (PP (IN over) (NP (DT the) (JJ lazy) (NN dog)))))))))\n",
      "                                ROOT                                  \n",
      "                                 |                                     \n",
      "                                 NP                                   \n",
      "                                 |                                     \n",
      "                                 S                                    \n",
      "            _____________________|____                                 \n",
      "           |                 |        S                               \n",
      "           |                 |    ____|___________                     \n",
      "           |                 |   |                VP                  \n",
      "           |                 |   |     ___________|____                \n",
      "           S                 |   |    |                VP             \n",
      "       ____|_______          |   |    |      __________|___            \n",
      "      |            VP        |   |    |     |              PP         \n",
      "      |         ___|____     |   |    |     |      ________|___        \n",
      "      NP       |       ADJP  |   NP   |     |     |            NP     \n",
      "  ____|____    |        |    |   |    |     |     |     _______|____   \n",
      " DT   JJ   NN VBZ       JJ   CC PRP  VBZ   VBG    IN   DT      JJ   NN\n",
      " |    |    |   |        |    |   |    |     |     |    |       |    |  \n",
      "The brown fox  is     quick and  he   is jumping over the     lazy dog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.stanford import StanfordParser\n",
    "\n",
    "sample_sentence = 'The brown fox is quick and he is jumping over the lazy dog'\n",
    "\n",
    "scp = StanfordParser(path_to_jar='C:/Users/shres/PythonDoc/text_analytics/stanford_parser/stanford-parser-full-2015-04-20/stanford-parser.jar',\n",
    "                     path_to_models_jar='C:/Users/shres/PythonDoc/text_analytics/stanford_parser/stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar')\n",
    "\n",
    "# get parse tree                   \n",
    "result = list(scp.raw_parse(sample_sentence))[0]\n",
    "print(result)\n",
    "result.pretty_print() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
